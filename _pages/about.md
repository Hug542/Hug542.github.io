---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<script>
      function dropdown(divID) {
          var item = document.getElementById(divID);
          if (item) {
              item.className=(item.className=='hidden')?'unhidden':'hidden';
          }
      }
</script>
  
<p style="text-align: center;"><i> ~~ I like to Observe. Look for Patterns. Ponder over these Generalizations. Try to Refute them. <br> &nbsp;&nbsp; Or otherwise prove their Validity. And re-image their Applications in alternate spheres ~~  </i></p>

Pratyush Maini
======
I work in the AI Solutions Lab at Samsung Research and Development Headquarters in South Korea. My broad area of interest lies in analyzing and developing robust, secure and explainable methods for machine learning and natural language processing. Previously, I completed my bachelors in Computer Science and Engineering from IIT Delhi.  

During my undergraduate years, I was fortunate to have had the opportunity to adapt and learn from the research styles of my amazing collaborators. I was advised by [Prof. Mausam](http://www.cse.iitd.ernet.in/~mausam/){:target="_blank"} for my B.Tech. thesis, and worked with [Prof. Zico Kolter](https://www.zicokolter.com){:target="_blank"}, [Eric Wong](https://www.cs.cmu.edu/~ericwong/){:target="_blank"}, [Danish](https://www.cs.cmu.edu/~ddanish/){:target="_blank"} at CMU, [Prof. Bo Li](https://aisecure.github.io){:target="_blank"}, [Prof. Dawn Song](https://people.eecs.berkeley.edu/~dawnsong/){:target="_blank"}, [Xinyun Chen](https://jungyhuk.github.io/){:target="_blank"} at UIUC/UC Berkeley, [Prof. Nicolas Papernot](https://www.papernot.fr){:target="_blank"} at UofT/Vector and [Prof. James Larus](https://people.epfl.ch/james.larus){:target="_blank"} at EPFL during research internships.

Recent News  <sub><sup><sub><sup>(Scroll for more)</sup></sub></sup></sub>
-----
<style>
table, tr, td {
    border: none;
}
pre {
	background-color: #f5f5f5;
	color: #110000;
	border: 3;
	font-size:0.8em;
	line-height:1.2em;
	max-width: 950px;
	whitewhite-space: pre-wrap;       /* css-3 */
	whitewhite-space: -pre-wrap;      /* Opera 4-6 */
	whitewhite-space: -o-pre-wrap;    /* Opera 7 */
	word-wrap: break-word;       /* Internet Explorer 5+ */
	whitewhite-space: -moz-pre-wrap;  /* Older Versions of Mozilla */
}
.hidden {
    display: none;
}
.unhidden {
    display: table;
    position:relative;
    width:100%;
}
</style>

<div style="height:150px;overflow:auto;border:0px;border-collapse: collapse;" >
<table  border="none" style="border:0px;border-collapse: collapse;" rules="none" >
<font face = "Times New Roman" size = "14">
<colgroup>
       <col span="1" style="width: 12%;">
       <col span="1" style="width: 88%;">
</colgroup>
<tr><td> Feb 2021:</td> <td> Work on <i>Data-Free Model Extraction</i> <a href="https://arxiv.org/abs/2011.14779">[Link]</a> was accepted at CVPR2021.</td> </tr>
<tr><td> Jan 2021:</td> <td> Work on <i>Dataset Inference</i> <a href="https://openreview.net/forum?id=hvdKKV2yt7T">[Link]</a> was accepted as a <i>Spotlight</i> at ICLR2021.</td> </tr>

<tr><td> Dec 2020:</td> <td> Preprint released for <i>Data-Free Model Extraction</i> <a href="https://arxiv.org/abs/2011.14779">[Link]</a>.</td> </tr>
  
<tr><td> Nov 2020:</td> <td> Work on <i>Dataset Inference: Ownership Resolution in Machine Learning</i> will be presented at PPML Workshop and WDCS at NeurIPS 2020. <a href="https://openreview.net/forum?id=hvdKKV2yt7T">[Link]</a> <a href="https://slideslive.com/38940925/dataset-inference-ownership-resolution-in-machine-learning">[Talk]</a>.</td> </tr>
  
<tr><td> Oct 2020:</td> <td> Started New Role at AI Soultions Lab in the Computer Vision Team at Samsung Research and Development Headquarters, South Korea.</td> </tr>
  
<tr><td> Sept 2020:</td> <td> Our paper <i>Why and when should you pool? Analyzing Pooling in Recurrent Architectures</i> was accepted at Findings of EMNLP 2020. Will also be presented at BlackBox NLP 2020.<a href="https://arxiv.org/abs/2005.0159">[Link] </a><a href="https://pratyushmaini.github.io/Pooling-Analysis/">[Blog]</a> </a><a href="https://pratyushmaini.github.io/Pooling-Analysis/">[Poster]</a>.</td> </tr>


<tr><td> July 2020:</td> <td> Completed my Bachelors of Technology in Computer Science and Engineering at IIT Delhi. Drop in at my thesis: <a href="https://pratyushmaini.github.io/files/BTech_Thesis_Pratyush_Maini.pdf">Analyzing the Learnability and Representability of Recurrent Architectures</a>.</td> </tr>
  
<tr><td> June 2020:</td> <td> New work on <i>Classifying Adversarial Perturbations</i> to be presented at <a href="https://sites.google.com/view/udlworkshop2020/">ICML 2020 Workshop</a> on Uncertainty & Robustness in Deep Learning.</td> </tr>
  
<tr><td> May 2020:</td> <td> Our paper <i>Adversarial Robustness Against the Union of Multiple Perturbation Models</i> was accepted at <a href="https://icml.cc/Conferences/2020/AcceptedPapersInitial">ICML 2020</a>.<a href="https://arxiv.org/abs/1909.04068">[Paper]</a> <a href="http://test.slideslive.com/38928141/adversarial-robustness-against-the-union-of-multiple-petrubation-models?ref=speaker-31494-latest">[Talk]</a>. </td> </tr>

<tr><td> May 2020: </td> <td> <a href="https://arxiv.org/abs/2005.00159">Preprint</a> released for <i>Why and when should you pool? Analyzing Pooling in Recurrent Architectures</i>. <br> See blog post <a href="https://pratyushmaini.github.io/Pooling-Analysis/">here</a>. </td> </tr>

<tr><td> April 2020: </td> <td> Our entry, <a href ="https://pratyushmaini.github.io/files/TheDelusional.pdf">The Delusional</a> (with artistic pieces, prose and poems in both English & Hindi) won the best Magazine in Gazettale 2020. </td></tr> 

<tr><td> Jan 2020: </td> <td> Started TAing the course "Data Structures & Algorithms" <a href= "https://pratyushmaini.github.io/teaching/2020-ds-ta">[Link]</a> . </td></tr> 

<tr><td> Dec 2019:</td> <td> Started (slowly) setting up my personal website. </td> </tr>

<tr><td> Sep 2019:</td> <td> <a href = "https://arxiv.org/abs/1909.04068">Preprint</a> released for <i>Adversarial Robustness Against the Union of Multiple Perturbation Models</i> </td> </tr>

<tr><td> Aug 2019: </td> <td> Started TAing the course "Introduction to Artificial Intelligence" <a href= "https://pratyushmaini.github.io/teaching/2019-ai">[Link]</a> (Graduate and Undergraduate bridge course). </td></tr> 

</font>
</table>
</div>



Publications
-----

[Dataset Inference: Ownership Resolution in Machine Learning](https://openreview.net/pdf?id=hvdKKV2yt7T){:target="_blank"}   
*Pratyush Maini, Mohammad Yaghini, Nicolas Papernot*   
International Conference on Learning Representations (**ICLR**) 2021 ![](https://img.shields.io/badge/-conference-brightgreen) ![](https://img.shields.io/badge/-spotlight-yellow)   
Privacy Preserving Machine Learning (**PPML**) Workshop at **NeurIPS** 2020 ![](https://img.shields.io/badge/-workshop-blue)   
Workshop on Dataset Curation and Security (**WDCS**) at **NeurIPS** 2020 ![](https://img.shields.io/badge/-workshop-blue)   
<a href="javascript:dropdown('di-tldr');">TLDR</a> | [Paper](https://openreview.net/forum?id=hvdKKV2yt7T){:target="_blank"} | [Video](https://slideslive.com/38940925/dataset-inference-ownership-resolution-in-machine-learning){:target="_blank"} | [Slides](files/DI/DI_Slides.pdf){:target="_blank"} | [Poster](files/DI/DI_Poster.pdf){:target="_blank"} | <a href="javascript:dropdown('di');">Citation</a>     
<div id="di-tldr" class="hidden"><b>TLDR:</b><ol>
		<li>Dataset Inference (DI) resolves model ownership without the need for retraining; and does not have a trade-off with task accuracy.</li>
		<li>We prove that the success of Membership Inference decreases as overfitting reduces, whereas DI is independent of the same.</li>
		<li>We introduce a new method for black-box ownership resolution that requires less than 50 private training points from the victim’s dataset.	</li>
	</ol>
<br><br> </div>

<div id="di" class="hidden">
<pre>@article{maini2021dataset,
	title={Dataset Inference: Ownership Resolution in Machine Learning},
	author={Pratyush Maini and Mohammad Yaghini and Nicolas Papernot},
	booktitle={ICLR 2021},
	year={2020},
	url={https://openreview.net/forum?id=hvdKKV2yt7T},
	note={Spotlight at ICLR 2021}
}</pre></div>   

    
[Data-Free Model Extraction](https://arxiv.org/abs/2011.14779){:target="_blank"}   
*Jean-Baptiste Truong\*, Pratyush Maini\*, Robert Walls, Nicolas Papernot*   
Conference on Computer Vision and Pattern Recognition (**CVPR**) 2021 ![](https://img.shields.io/badge/-conference-brightgreen)    
<a href="javascript:dropdown('dfme-tldr');">TLDR</a> | [Paper](https://arxiv.org/abs/2011.14779){:target="_blank"} | [Code](https://github.com/cake-lab/datafree-model-extraction){:target="_blank"} | [Poster](files/DI/DI_Poster.pdf){:target="_blank"} | <a href="javascript:dropdown('dfme');">Citation</a>     
<div id="dfme-tldr" class="hidden"><b>TLDR:</b> We analyze the importance of similarity between surrogate & victim datasets for the success of model stealing attacks, and develop a method to steal ML models with zero knowledge of the victim’s training data.<br><br> </div>
<div id="dfme" class="hidden">
<pre>@article{truong2021data,
	title={Data-Free Model Extraction},
	author={Jean-Baptiste Truong* and Pratyush Maini* and Robert J. Walls and Nicolas Papernot},
	booktitle={arXiv preprint arXiv:2011.14779},
	year={2021},
	url={https://arxiv.org/abs/2011.14779},
	note={under review at CVPR 2021},
}</pre></div>

[Adversarial Robustness Against the Union of Multiple Perturbation Models](https://arxiv.org/abs/1909.04068){:target="_blank"}   
*Pratyush Maini, Eric Wong, Zico Kolter*   
International Conference on Machine Learning (**ICML**) 2020 ![](https://img.shields.io/badge/-conference-brightgreen)   
<a href="javascript:dropdown('multiple-tldr');">TLDR</a> | [Paper](https://arxiv.org/abs/1909.04068){:target="_blank"} | [Video](http://test.slideslive.com/38928141/adversarial-robustness-against-the-union-of-multiple-petrubation-models?ref=speaker-31494-latest){:target="_blank"} | [Slides](/files/MSD/robust_union.pdf){:target="_blank"} | [Code](https://github.com/locuslab/robust_union){:target="_blank"} | <a href="javascript:dropdown('multiple');">Citation</a>  
<div id="multiple-tldr" class="hidden"><b>TLDR:</b> We develop a generalization of the standard PGD-based procedure to train architectures which are robust against multiple perturbation models, outperforming past approaches on the MNIST and CIFAR10 datasets.<br><br> </div>
<div id="multiple" class="hidden">
<pre>@inproceedings{maini2020adversarial,
	title={Adversarial Robustness Against the Union of Multiple Perturbation Models}, 
	author={Pratyush Maini and Eric Wong and J. Zico Kolter},
	booktitle={International Conference on Machine Learning},
	year={2020},
	url = "https://arxiv.org/abs/1909.04068"
}</pre></div>
    
[Why and when should you pool? Analyzing Pooling in Recurrent Architectures](https://arxiv.org/abs/2005.00159){:target="_blank"}   
*Pratyush Maini, Keshav Kolluru, Danish Pruthi, Mausam*   
**EMNLP** (Findings) 2020 ![](https://img.shields.io/badge/-conference-brightgreen)   
**BlackBoxNLP** 2020 ![](https://img.shields.io/badge/-workshop-blue)   
<a href="javascript:dropdown('pooling-tldr');">TLDR</a> | [Paper](https://arxiv.org/abs/1909.04068){:target="_blank"} | [Video](){:target="_blank"} | [Slides](files/Pooling/Pooling_slides.pdf){:target="_blank"} | [Code](https://github.com/dair-iitd/PoolingAnalysis){:target="_blank"} | [Blog](https://pratyushmaini.github.io/Pooling-Analysis){:target="_blank"} | [Poster](files/Pooling/Pooling_Poster.pdf){:target="_blank"} | <a href="javascript:dropdown('pooling');">Citation</a>     
<div id="pooling-tldr" class="hidden"><b>TLDR:</b><ol>
	<li> Pooling (and attention) help improve learning ability and positional invariance of BiLSTMs. </li>
	<li> Pooling helps improve sample efficiency (low-resource settings) and is particularly beneficial when important words lie away from the end of the sentence. </li>
	<li> Our proposed pooling technique, max-attention (MaxAtt), helps improve upon past approaches on standard accuracy metrics, and is more robust to distribution shift. </li>
	</ol><br><br> </div>
<div id="pooling" class="hidden">
<pre>@inproceedings{maini2020pool,
	title = "Why and when should you pool? Analyzing Pooling in Recurrent Architectures",
	author = "Maini, Pratyush and Kolluru, Keshav and Pruthi, Danish and {Mausam}",
	booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/2020.findings-emnlp.410",
	note = {Also presented at BlackBoxNLP'20}
}</pre></div>
    
    
[Perturbation Type Categorization for Multiple $\ell_p$ Bounded Adversarial Robustness](https://openreview.net/pdf?id=Oe2XI-Aft-k){:target="_blank"} ![](https://img.shields.io/badge/-in_submission-lightgrey)   
*Pratyush Maini, Xinyun Chen, Bo Li, Dawn Song*   
**ICML** Workshop on Uncertainty and Robustness in Deep Learning 2020 ![](https://img.shields.io/badge/-workshop-blue)      
<a href="javascript:dropdown('protector-tldr');">TLDR</a> | [Paper](https://openreview.net/pdf?id=Oe2XI-Aft-k){:target="_blank"} | <a href="javascript:dropdown('protector');">Citation</a>     
<div id="protector-tldr" class="hidden"><b>TLDR:</b> We demonstrate that adversarial perturbations belonging to different threat models can be separated, and use this intuition to propose a two stage pipeline <i>PROTECTOR</i> that is robust against multiple perturbation types.<br><br> </div>
<div id="protector" class="hidden">
<pre>@article{maini2021perturbation,
	title={Perturbation Type Categorization for Multiple $\ell_p$ Bounded Adversarial Robustness},
	author={Pratyush Maini and Xinyun Chen and Bo Li and Dawn Song},
	booktitle={ICML Workshop on Uncertainty and Robustness in Deep Learning},
	year={2020},
	url={https://openreview.net/pdf?id=Oe2XI-Aft-k},
}</pre></div>

    
-----
\* = equal contribution


---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
<p style="text-align: center;"><i> ~~ I like to Observe. Look for Patterns. Ponder over these Generalizations. Try to Refute them. <br> &nbsp;&nbsp; Or otherwise prove their Validity. And re-image their Applications in alternate spheres ~~  </i></p>

Pratyush Maini
======
I am a Final Year Undergraduate Student of Computer Science and Engineering at IIT Delhi. My broad area of interest lies in analyzing and developing robust, secure and explainable methods for machine learning and natural language processing. I am advised by [Prof. Mausam](http://www.cse.iitd.ernet.in/~mausam/) for my B.Tech. thesis. 

During my undergraduate years, I have been fortunate to have had the opportunity to adapt and learn from the research styles of my amazing collaborators: [Prof. Zico Kolter](https://www.zicokolter.com), [Eric Wong](https://www.cs.cmu.edu/~ericwong/), [Danish](https://www.cs.cmu.edu/~ddanish/) at CMU, [Prof. Bo Li](https://aisecure.github.io), [Prof. Dawn Song](https://people.eecs.berkeley.edu/~dawnsong/), [Xinyun Chen](https://jungyhuk.github.io/) at UIUC/UC Berkeley, [Prof. Nicolas Papernot](https://www.papernot.fr) at UofT/Vector and [Prof. James Larus](https://people.epfl.ch/james.larus) at EPFL during research internships.

Recent News  <sub><sup><sub><sup>(Scroll for more)</sup></sub></sup></sub>
-----
<style>
table, tr, td {
    border: none;
}
ul.pubs > li{
	margin-bottom: 1.2em;
}
.posts-wrapper {
	max-width: 1000px;
	margin-left:auto;
	margin-right:auto;
}
.clear{
    clear:both;
}
pre {
	background-color: #f5f5f5;
	color: #110000;
	border: 3;
	font-size:0.9em;
	line-height:1.2em;
	max-width: 950px;
	whitewhite-space: pre-wrap;       /* css-3 */
	whitewhite-space: -pre-wrap;      /* Opera 4-6 */
	whitewhite-space: -o-pre-wrap;    /* Opera 7 */
	word-wrap: break-word;       /* Internet Explorer 5+ */
	whitewhite-space: -moz-pre-wrap;  /* Older Versions of Mozilla */
}
.hidden {
    display: none;
}
.unhidden {
    display: table;
    position:relative;
/*    width:80%;*/
}
</style>

<div style="height:150px;overflow:auto;border:0px;border-collapse: collapse;" >
<table  border="none" style="border:0px;border-collapse: collapse;" rules="none" >
<font face = "Times New Roman" size = "14">
<colgroup>
       <col span="1" style="width: 12%;">
       <col span="1" style="width: 88%;">
</colgroup>
<tr><td> Dec 2020:</td> <td> Preprint released for <i>Data-Free Model Extraction</i> <a href="https://arxiv.org/abs/2011.14779">[Link]</a>.</td> </tr>
  
<tr><td> Nov 2020:</td> <td> Work on <i>Dataset Inference: Ownership Resolution in Machine Learning</i> will be presented at PPML Workshop and WDCS at NeurIPS 2020. <a href="https://openreview.net/forum?id=hvdKKV2yt7T">[Link]</a> <a href="https://slideslive.com/38940925/dataset-inference-ownership-resolution-in-machine-learning">[Talk]</a>.</td> </tr>
  
<tr><td> Oct 2020:</td> <td> Started New Role at AI Soultions Lab in the Computer Vision Team at Samsung Research and Development Headquarters, South Korea.</td> </tr>
  
<tr><td> Sept 2020:</td> <td> Our paper <i>Why and when should you pool? Analyzing Pooling in Recurrent Architectures</i> was accepted at Findings of EMNLP 2020. Will also be presented at BlackBox NLP 2020.<a href="https://arxiv.org/abs/2005.0159">[Link] </a><a href="https://pratyushmaini.github.io/Pooling-Analysis/">[Blog]</a> </a><a href="https://pratyushmaini.github.io/Pooling-Analysis/">[Poster]</a>.</td> </tr>


<tr><td> July 2020:</td> <td> Completed my Bachelors of Technology in Computer Science and Engineering at IIT Delhi. Drop in at my thesis: <a href="https://pratyushmaini.github.io/files/BTech_Thesis_Pratyush_Maini.pdf">Analyzing the Learnability and Representability of Recurrent Architectures</a>.</td> </tr>
  
<tr><td> June 2020:</td> <td> New work on <i>Classifying Adversarial Perturbations</i> to be presented at <a href="https://sites.google.com/view/udlworkshop2020/">ICML 2020 Workshop</a> on Uncertainty & Robustness in Deep Learning.</td> </tr>
  
<tr><td> May 2020:</td> <td> Our paper <i>Adversarial Robustness Against the Union of Multiple Perturbation Models</i> was accepted at <a href="https://icml.cc/Conferences/2020/AcceptedPapersInitial">ICML 2020</a>.<a href="https://arxiv.org/abs/1909.04068">[Paper]</a> <a href="http://test.slideslive.com/38928141/adversarial-robustness-against-the-union-of-multiple-petrubation-models?ref=speaker-31494-latest">[Talk]</a>. </td> </tr>

<tr><td> May 2020: </td> <td> <a href="https://arxiv.org/abs/2005.00159">Preprint</a> released for <i>Why and when should you pool? Analyzing Pooling in Recurrent Architectures</i>. <br> See blog post <a href="https://pratyushmaini.github.io/Pooling-Analysis/">here</a>. </td> </tr>

<tr><td> April 2020: </td> <td> Our entry, <a href ="https://pratyushmaini.github.io/files/TheDelusional.pdf">The Delusional</a> (with artistic pieces, prose and poems in both English & Hindi) won the best Magazine in Gazettale 2020. </td></tr> 

<tr><td> Jan 2020: </td> <td> Started TAing the course "Data Structures & Algorithms" <a href= "https://pratyushmaini.github.io/teaching/2020-ds-ta">[Link]</a> . </td></tr> 

<tr><td> Dec 2019:</td> <td> Started (slowly) setting up my personal website. </td> </tr>

<tr><td> Sep 2019:</td> <td> <a href = "https://arxiv.org/abs/1909.04068">Preprint</a> released for <i>Adversarial Robustness Against the Union of Multiple Perturbation Models</i> </td> </tr>

<tr><td> Aug 2019: </td> <td> Started TAing the course "Introduction to Artificial Intelligence" <a href= "https://pratyushmaini.github.io/teaching/2019-ai">[Link]</a> (Graduate and Undergraduate bridge course). </td></tr> 

</font>
</table>
</div>



Publications
-----

[Adversarial Robustness Against the Union of Multiple Perturbation Models](https://arxiv.org/abs/1909.04068)   
*Pratyush Maini, Eric Wong, Zico Kolter*   
International Conference on Machine Learning (**ICML**) 2020 ![](https://img.shields.io/badge/-conference-brightgreen)   
[TLDR]() | [Paper](https://arxiv.org/abs/1909.04068) | [Video](http://test.slideslive.com/38928141/adversarial-robustness-against-the-union-of-multiple-petrubation-models?ref=speaker-31494-latest) | [Slides]() | [Code](https://github.com/locuslab/robust_union) | [Citation]()   

[Why and when should you pool? Analyzing Pooling in Recurrent Architectures](https://arxiv.org/abs/2005.00159)   
*Pratyush Maini, Keshav Kolluru, Danish Pruthi, Mausam*   
**EMNLP** (Findings) 2020 ![](https://img.shields.io/badge/-conference-brightgreen)   
**BlackBoxNLP** 2020 ![](https://img.shields.io/badge/-workshop-blue)   
[TLDR]() | [Paper](https://arxiv.org/abs/1909.04068) | [Video]() | [Slides]() | [Code](https://github.com/dair-iitd/PoolingAnalysis) | [Blog](https://pratyushmaini.github.io/Pooling-Analysis) | [Poster]() | [Citation]()   

[Dataset Inference: Ownership Resolution in Machine Learning](https://openreview.net/pdf?id=hvdKKV2yt7T)   
*Pratyush Maini, Mohammad Yaghini, Nicolas Papernot*   
Privacy Preserving Machine Learning (**PPML**) Workshop at **NeurIPS** 2020 ![](https://img.shields.io/badge/-workshop-blue)   
Workshop on Dataset Curation and Security (**WDCS**) at **NeurIPS** 2020 ![](https://img.shields.io/badge/-workshop-blue)   
Under Review at **ICLR** 2021 ![](https://img.shields.io/badge/-submitted-lightgrey)   
[TLDR]() | [Paper](https://openreview.net/pdf?id=hvdKKV2yt7T) | [Video](https://slideslive.com/38940925/dataset-inference-ownership-resolution-in-machine-learning) | [Slides]()    

[Perturbation Type Categorization for Multiple $\ell_p$ Bounded Adversarial Robustness](https://openreview.net/pdf?id=Oe2XI-Aft-k)   
*Pratyush Maini, Xinyun Chen, Bo Li, Dawn Song*   
**ICML** Workshop on Uncertainty and Robustness in Deep Learning 2020 ![](https://img.shields.io/badge/-workshop-blue)   
Under Review at **ICLR** 2021 ![](https://img.shields.io/badge/-submitted-lightgrey)   
[TLDR]() | [Paper](https://openreview.net/pdf?id=Oe2XI-Aft-k)   

[Data-Free Model Extraction](https://arxiv.org/abs/2011.14779)   
*Jean-Baptiste Truong\*, Pratyush Maini\*, Robert Walls, Nicolas Papernot*   
Under Review at **CVPR** 2021 ![](https://img.shields.io/badge/-submitted-lightgrey)   
[TLDR]() | [Paper](https://arxiv.org/abs/2011.14779) | [Code](https://github.com/cake-lab/datafree-model-extraction) | [Citation]()   

-----
\* = equal contribution

<a href="https://arxiv.org/abs/2010.12563" target="_blank" style="color:black;font-size:1.0em">
          Customizing Triggers with Concealed Data Poisoning</a><br>
          Eric Wallace*, Tony Z. Zhao*, Shi Feng, and Sameer Singh<br>
          <i>arXiv preprint</i><br>
          <a href="javascript:unhide('poisoning20tldr');">TLDR</a> | <a href="http://ericswallace.com/poisoning" target="_blank">Blog</a> | <a href="https://twitter.com/Eric_Wallace_/status/1319650623705370624" target="_blank">Twitter</a> | <a href="https://arxiv.org/abs/2010.12563" target="_blank">Paper</a> | <a href="https://github.com/Eric-Wallace/data-poisoning" target="_blank">Code</a> | <a href="javascript:unhide('poisoning20');">Citation</a>
          <div id="poisoning20tldr" class="hidden"><b>TLDR:</b> We develop a new training data poisoning attack that allows an adversary to control model predictions whenever a desired phrase is present in the input.<br></div>
        <div id="poisoning20" class="hidden">
        <pre>@article{wallace2020poisoning,
            title={Customizing Triggers with Concealed Data Poisoning},
            author={Eric Wallace and Tony Z. Zhao and Shi Feng and Sameer Singh},
            journal={arXiv preprint arXiv:2010.12563},
            year={2020}}
         </pre>
         </div>
	 
<!--
<div class="posts-wrapper" style="clear:both">
    <h3 style="margin-bottom:0.75em;">Publications</h3>
    </i>
    <p>

    <ul class="pubs">

    <li>
                <a href="https://arxiv.org/abs/1804.07781" target="_blank" style="color:black;font-size:1.0em">Pathologies of Neural Models Make Interpretations Difficult</a><br>
                Shi Feng, Eric Wallace, Alvin Grissom II, Mohit Iyyer, Pedro Rodriguez, Jordan Boyd-Graber<br>
                <i>EMNLP 2018</i><br>
                <a href="javascript:unhide('pathological18tldr');">TLDR</a> | <a href="https://vimeo.com/306158589" target="_blank">Video</a> | <a href="https://arxiv.org/abs/1804.07781" target="_blank">Paper</a> |
                <a href="slides_and_posters/pathologies_slides.pdf" target="_blank">Slides</a> | <a href="https://github.com/allenai/allennlp/blob/master/allennlp/interpret/attackers/input_reduction.py" target="_blank">Code</a> | <a href="javascript:unhide('pathological18');">Citation</a>
                <div id="pathological18tldr" class="hidden"><b>TLDR:</b> Saliency maps are a popular interpretation technique. We show that certain pathological behavior present in neural models (namely prediction overconfidence) can negatively impact these interpretations.<br> </div>
                <div id="pathological18" class="hidden">
                    <pre>@inproceedings{Feng2018Pathological,
    Author = {Shi Feng and Eric Wallace and Alvin Grissom II and Mohit Iyyer and Pedro Rodriguez and Jordan Boyd-Graber},
    Booktitle = {Empirical Methods in Natural Language Processing},
    Year = {2018},
    Title = {Pathologies of Neural Models Make Interpretations Difficult}}
                  </pre>
                </div>
            </li>
        </ul>
    </p>


<details>
<summary>Example</summary>
This is a dropdown with text!
</details>
-->
